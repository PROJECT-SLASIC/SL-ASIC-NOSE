{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aefb79de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index0</th>\n",
       "      <th>index1</th>\n",
       "      <th>index2</th>\n",
       "      <th>index3</th>\n",
       "      <th>index4</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.366564</td>\n",
       "      <td>0.625748</td>\n",
       "      <td>0.389866</td>\n",
       "      <td>0.616685</td>\n",
       "      <td>0.568842</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.397135</td>\n",
       "      <td>0.661726</td>\n",
       "      <td>0.410426</td>\n",
       "      <td>0.640351</td>\n",
       "      <td>0.607502</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.423907</td>\n",
       "      <td>0.700379</td>\n",
       "      <td>0.426792</td>\n",
       "      <td>0.655281</td>\n",
       "      <td>0.620554</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.448317</td>\n",
       "      <td>0.724839</td>\n",
       "      <td>0.467309</td>\n",
       "      <td>0.684586</td>\n",
       "      <td>0.655065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.477561</td>\n",
       "      <td>0.740232</td>\n",
       "      <td>0.506941</td>\n",
       "      <td>0.700898</td>\n",
       "      <td>0.676642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index0    index1    index2    index3    index4  Label\n",
       "0  0.366564  0.625748  0.389866  0.616685  0.568842      0\n",
       "1  0.397135  0.661726  0.410426  0.640351  0.607502      0\n",
       "2  0.423907  0.700379  0.426792  0.655281  0.620554      0\n",
       "3  0.448317  0.724839  0.467309  0.684586  0.655065      0\n",
       "4  0.477561  0.740232  0.506941  0.700898  0.676642      0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('5data.csv')\n",
    "data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0870d1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.initializers import RandomNormal, RandomUniform\n",
    "from tensorflow.keras.initializers import GlorotNormal, GlorotUniform\n",
    "\n",
    "# Load standardized data\n",
    "data = pd.read_csv('5data.csv')\n",
    "X = data[['index0','index1','index2','index3','index4']].values\n",
    "y = data[['Label']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ac80f374",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "20/20 [==============================] - 1s 7ms/step - loss: 1.7569 - accuracy: 0.2853 - val_loss: 1.7332 - val_accuracy: 0.2941\n",
      "Epoch 2/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.7282 - accuracy: 0.2853 - val_loss: 1.7052 - val_accuracy: 0.2941\n",
      "Epoch 3/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.7020 - accuracy: 0.2853 - val_loss: 1.6730 - val_accuracy: 0.2941\n",
      "Epoch 4/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.6708 - accuracy: 0.2853 - val_loss: 1.6337 - val_accuracy: 0.2941\n",
      "Epoch 5/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.6346 - accuracy: 0.3344 - val_loss: 1.5938 - val_accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.5959 - accuracy: 0.5008 - val_loss: 1.5471 - val_accuracy: 0.5588\n",
      "Epoch 7/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.5524 - accuracy: 0.5040 - val_loss: 1.4960 - val_accuracy: 0.5588\n",
      "Epoch 8/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.5041 - accuracy: 0.5040 - val_loss: 1.4335 - val_accuracy: 0.5588\n",
      "Epoch 9/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.4474 - accuracy: 0.5040 - val_loss: 1.3711 - val_accuracy: 0.5588\n",
      "Epoch 10/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.3887 - accuracy: 0.5040 - val_loss: 1.3053 - val_accuracy: 0.5588\n",
      "Epoch 11/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.3295 - accuracy: 0.5040 - val_loss: 1.2376 - val_accuracy: 0.5588\n",
      "Epoch 12/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.2703 - accuracy: 0.5040 - val_loss: 1.1756 - val_accuracy: 0.5588\n",
      "Epoch 13/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.2146 - accuracy: 0.5040 - val_loss: 1.1150 - val_accuracy: 0.5588\n",
      "Epoch 14/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.1633 - accuracy: 0.5040 - val_loss: 1.0637 - val_accuracy: 0.5588\n",
      "Epoch 15/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.1174 - accuracy: 0.5040 - val_loss: 1.0178 - val_accuracy: 0.5588\n",
      "Epoch 16/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.0759 - accuracy: 0.5040 - val_loss: 0.9767 - val_accuracy: 0.5588\n",
      "Epoch 17/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.0383 - accuracy: 0.5246 - val_loss: 0.9393 - val_accuracy: 0.6471\n",
      "Epoch 18/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.0031 - accuracy: 0.5784 - val_loss: 0.9026 - val_accuracy: 0.6765\n",
      "Epoch 19/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.9698 - accuracy: 0.5864 - val_loss: 0.8715 - val_accuracy: 0.6765\n",
      "Epoch 20/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.9363 - accuracy: 0.5864 - val_loss: 0.8399 - val_accuracy: 0.6765\n",
      "Epoch 21/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.9037 - accuracy: 0.5959 - val_loss: 0.8091 - val_accuracy: 0.6765\n",
      "Epoch 22/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.8726 - accuracy: 0.6149 - val_loss: 0.7801 - val_accuracy: 0.7059\n",
      "Epoch 23/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.8426 - accuracy: 0.6561 - val_loss: 0.7513 - val_accuracy: 0.7059\n",
      "Epoch 24/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.8136 - accuracy: 0.7005 - val_loss: 0.7245 - val_accuracy: 0.7353\n",
      "Epoch 25/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.7859 - accuracy: 0.7306 - val_loss: 0.7003 - val_accuracy: 0.7353\n",
      "Epoch 26/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.7597 - accuracy: 0.7544 - val_loss: 0.6764 - val_accuracy: 0.8235\n",
      "Epoch 27/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.7352 - accuracy: 0.7623 - val_loss: 0.6545 - val_accuracy: 0.8235\n",
      "Epoch 28/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.7129 - accuracy: 0.7639 - val_loss: 0.6363 - val_accuracy: 0.8235\n",
      "Epoch 29/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.7639 - val_loss: 0.6174 - val_accuracy: 0.8235\n",
      "Epoch 30/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6727 - accuracy: 0.7639 - val_loss: 0.6003 - val_accuracy: 0.8235\n",
      "Epoch 31/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.7623 - val_loss: 0.5874 - val_accuracy: 0.8235\n",
      "Epoch 32/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6376 - accuracy: 0.7639 - val_loss: 0.5720 - val_accuracy: 0.8235\n",
      "Epoch 33/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6231 - accuracy: 0.7639 - val_loss: 0.5601 - val_accuracy: 0.8235\n",
      "Epoch 34/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6095 - accuracy: 0.7623 - val_loss: 0.5458 - val_accuracy: 0.8235\n",
      "Epoch 35/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5976 - accuracy: 0.7623 - val_loss: 0.5379 - val_accuracy: 0.8235\n",
      "Epoch 36/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5851 - accuracy: 0.7655 - val_loss: 0.5261 - val_accuracy: 0.8235\n",
      "Epoch 37/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.7623 - val_loss: 0.5184 - val_accuracy: 0.8235\n",
      "Epoch 38/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.7639 - val_loss: 0.5086 - val_accuracy: 0.8235\n",
      "Epoch 39/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7623 - val_loss: 0.5009 - val_accuracy: 0.8235\n",
      "Epoch 40/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7623 - val_loss: 0.4936 - val_accuracy: 0.8235\n",
      "Epoch 41/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7639 - val_loss: 0.4862 - val_accuracy: 0.8235\n",
      "Epoch 42/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.7639 - val_loss: 0.4839 - val_accuracy: 0.8235\n",
      "Epoch 43/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7623 - val_loss: 0.4751 - val_accuracy: 0.8235\n",
      "Epoch 44/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7639 - val_loss: 0.4713 - val_accuracy: 0.8235\n",
      "Epoch 45/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7639 - val_loss: 0.4647 - val_accuracy: 0.8235\n",
      "Epoch 46/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7639 - val_loss: 0.4589 - val_accuracy: 0.8235\n",
      "Epoch 47/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.7639 - val_loss: 0.4568 - val_accuracy: 0.8235\n",
      "Epoch 48/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7639 - val_loss: 0.4521 - val_accuracy: 0.8235\n",
      "Epoch 49/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7639 - val_loss: 0.4466 - val_accuracy: 0.8235\n",
      "Epoch 50/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7655 - val_loss: 0.4445 - val_accuracy: 0.8235\n",
      "Epoch 51/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7702 - val_loss: 0.4413 - val_accuracy: 0.8235\n",
      "Epoch 52/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7686 - val_loss: 0.4363 - val_accuracy: 0.8235\n",
      "Epoch 53/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7813 - val_loss: 0.4341 - val_accuracy: 0.8235\n",
      "Epoch 54/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7845 - val_loss: 0.4299 - val_accuracy: 0.8235\n",
      "Epoch 55/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7908 - val_loss: 0.4269 - val_accuracy: 0.8235\n",
      "Epoch 56/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7956 - val_loss: 0.4247 - val_accuracy: 0.8235\n",
      "Epoch 57/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.8051 - val_loss: 0.4246 - val_accuracy: 0.8235\n",
      "Epoch 58/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.8082 - val_loss: 0.4188 - val_accuracy: 0.8235\n",
      "Epoch 59/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.8067 - val_loss: 0.4176 - val_accuracy: 0.8235\n",
      "Epoch 60/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.8114 - val_loss: 0.4125 - val_accuracy: 0.8235\n",
      "Epoch 61/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8177 - val_loss: 0.4127 - val_accuracy: 0.8529\n",
      "Epoch 62/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8225 - val_loss: 0.4103 - val_accuracy: 0.8529\n",
      "Epoch 63/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.8257 - val_loss: 0.4035 - val_accuracy: 0.8529\n",
      "Epoch 64/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.8320 - val_loss: 0.4051 - val_accuracy: 0.8529\n",
      "Epoch 65/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.8368 - val_loss: 0.4027 - val_accuracy: 0.8529\n",
      "Epoch 66/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8320 - val_loss: 0.3963 - val_accuracy: 0.8529\n",
      "Epoch 67/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.8336 - val_loss: 0.3982 - val_accuracy: 0.8529\n",
      "Epoch 68/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.8463 - val_loss: 0.3931 - val_accuracy: 0.8529\n",
      "Epoch 69/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8447 - val_loss: 0.3924 - val_accuracy: 0.8529\n",
      "Epoch 70/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8447 - val_loss: 0.3897 - val_accuracy: 0.8529\n",
      "Epoch 71/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8494 - val_loss: 0.3877 - val_accuracy: 0.8529\n",
      "Epoch 72/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.8526 - val_loss: 0.3868 - val_accuracy: 0.8529\n",
      "Epoch 73/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3841 - accuracy: 0.8510 - val_loss: 0.3830 - val_accuracy: 0.8529\n",
      "Epoch 74/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8542 - val_loss: 0.3810 - val_accuracy: 0.8529\n",
      "Epoch 75/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8542 - val_loss: 0.3787 - val_accuracy: 0.8529\n",
      "Epoch 76/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8558 - val_loss: 0.3761 - val_accuracy: 0.8529\n",
      "Epoch 77/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8558 - val_loss: 0.3773 - val_accuracy: 0.8529\n",
      "Epoch 78/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8542 - val_loss: 0.3718 - val_accuracy: 0.8529\n",
      "Epoch 79/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8558 - val_loss: 0.3708 - val_accuracy: 0.8529\n",
      "Epoch 80/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8558 - val_loss: 0.3684 - val_accuracy: 0.8529\n",
      "Epoch 81/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8542 - val_loss: 0.3693 - val_accuracy: 0.8529\n",
      "Epoch 82/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8558 - val_loss: 0.3616 - val_accuracy: 0.8529\n",
      "Epoch 83/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8558 - val_loss: 0.3681 - val_accuracy: 0.8529\n",
      "Epoch 84/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3490 - accuracy: 0.8558 - val_loss: 0.3587 - val_accuracy: 0.8529\n",
      "Epoch 85/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3463 - accuracy: 0.8558 - val_loss: 0.3592 - val_accuracy: 0.8529\n",
      "Epoch 86/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.8558 - val_loss: 0.3590 - val_accuracy: 0.8529\n",
      "Epoch 87/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8542 - val_loss: 0.3551 - val_accuracy: 0.8529\n",
      "Epoch 88/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3383 - accuracy: 0.8558 - val_loss: 0.3545 - val_accuracy: 0.8529\n",
      "Epoch 89/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8542 - val_loss: 0.3542 - val_accuracy: 0.8529\n",
      "Epoch 90/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8574 - val_loss: 0.3470 - val_accuracy: 0.8529\n",
      "Epoch 91/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8542 - val_loss: 0.3504 - val_accuracy: 0.8529\n",
      "Epoch 92/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8574 - val_loss: 0.3454 - val_accuracy: 0.8529\n",
      "Epoch 93/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8542 - val_loss: 0.3472 - val_accuracy: 0.8529\n",
      "Epoch 94/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8558 - val_loss: 0.3453 - val_accuracy: 0.8529\n",
      "Epoch 95/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3215 - accuracy: 0.8558 - val_loss: 0.3412 - val_accuracy: 0.8529\n",
      "Epoch 96/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8542 - val_loss: 0.3425 - val_accuracy: 0.8529\n",
      "Epoch 97/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8558 - val_loss: 0.3381 - val_accuracy: 0.8529\n",
      "Epoch 98/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8558 - val_loss: 0.3385 - val_accuracy: 0.8529\n",
      "Epoch 99/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3140 - accuracy: 0.8558 - val_loss: 0.3372 - val_accuracy: 0.8529\n",
      "Epoch 100/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.8574 - val_loss: 0.3327 - val_accuracy: 0.8529\n",
      "Epoch 101/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8558 - val_loss: 0.3350 - val_accuracy: 0.8529\n",
      "Epoch 102/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8558 - val_loss: 0.3311 - val_accuracy: 0.8529\n",
      "Epoch 103/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8558 - val_loss: 0.3336 - val_accuracy: 0.8529\n",
      "Epoch 104/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3029 - accuracy: 0.8558 - val_loss: 0.3274 - val_accuracy: 0.8529\n",
      "Epoch 105/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3006 - accuracy: 0.8558 - val_loss: 0.3280 - val_accuracy: 0.8529\n",
      "Epoch 106/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3002 - accuracy: 0.8558 - val_loss: 0.3242 - val_accuracy: 0.8529\n",
      "Epoch 107/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.8558 - val_loss: 0.3256 - val_accuracy: 0.8529\n",
      "Epoch 108/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2953 - accuracy: 0.8574 - val_loss: 0.3232 - val_accuracy: 0.8529\n",
      "Epoch 109/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2929 - accuracy: 0.8574 - val_loss: 0.3210 - val_accuracy: 0.8529\n",
      "Epoch 110/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2926 - accuracy: 0.8558 - val_loss: 0.3195 - val_accuracy: 0.8529\n",
      "Epoch 111/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2898 - accuracy: 0.8558 - val_loss: 0.3218 - val_accuracy: 0.8529\n",
      "Epoch 112/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2883 - accuracy: 0.8558 - val_loss: 0.3171 - val_accuracy: 0.8529\n",
      "Epoch 113/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2873 - accuracy: 0.8574 - val_loss: 0.3170 - val_accuracy: 0.8529\n",
      "Epoch 114/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2858 - accuracy: 0.8558 - val_loss: 0.3146 - val_accuracy: 0.8529\n",
      "Epoch 115/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2831 - accuracy: 0.8558 - val_loss: 0.3156 - val_accuracy: 0.8529\n",
      "Epoch 116/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2820 - accuracy: 0.8574 - val_loss: 0.3147 - val_accuracy: 0.8529\n",
      "Epoch 117/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2804 - accuracy: 0.8558 - val_loss: 0.3116 - val_accuracy: 0.8529\n",
      "Epoch 118/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2811 - accuracy: 0.8558 - val_loss: 0.3111 - val_accuracy: 0.8529\n",
      "Epoch 119/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2773 - accuracy: 0.8574 - val_loss: 0.3095 - val_accuracy: 0.8529\n",
      "Epoch 120/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2769 - accuracy: 0.8558 - val_loss: 0.3100 - val_accuracy: 0.8529\n",
      "Epoch 121/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2749 - accuracy: 0.8558 - val_loss: 0.3045 - val_accuracy: 0.8529\n",
      "Epoch 122/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2744 - accuracy: 0.8574 - val_loss: 0.3105 - val_accuracy: 0.8529\n",
      "Epoch 123/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2722 - accuracy: 0.8558 - val_loss: 0.3029 - val_accuracy: 0.8529\n",
      "Epoch 124/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2707 - accuracy: 0.8558 - val_loss: 0.3077 - val_accuracy: 0.8529\n",
      "Epoch 125/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2698 - accuracy: 0.8526 - val_loss: 0.3030 - val_accuracy: 0.8529\n",
      "Epoch 126/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2686 - accuracy: 0.8574 - val_loss: 0.3047 - val_accuracy: 0.8529\n",
      "Epoch 127/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2669 - accuracy: 0.8574 - val_loss: 0.2998 - val_accuracy: 0.8529\n",
      "Epoch 128/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2654 - accuracy: 0.8463 - val_loss: 0.3020 - val_accuracy: 0.8529\n",
      "Epoch 129/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2660 - accuracy: 0.8574 - val_loss: 0.2984 - val_accuracy: 0.8529\n",
      "Epoch 130/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2632 - accuracy: 0.8558 - val_loss: 0.2982 - val_accuracy: 0.8529\n",
      "Epoch 131/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2621 - accuracy: 0.8574 - val_loss: 0.2941 - val_accuracy: 0.8529\n",
      "Epoch 132/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2598 - accuracy: 0.8574 - val_loss: 0.2998 - val_accuracy: 0.8529\n",
      "Epoch 133/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2590 - accuracy: 0.8558 - val_loss: 0.2931 - val_accuracy: 0.8529\n",
      "Epoch 134/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.8574 - val_loss: 0.2910 - val_accuracy: 0.8529\n",
      "Epoch 135/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2565 - accuracy: 0.8558 - val_loss: 0.2954 - val_accuracy: 0.8529\n",
      "Epoch 136/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2551 - accuracy: 0.8574 - val_loss: 0.2916 - val_accuracy: 0.8529\n",
      "Epoch 137/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2544 - accuracy: 0.8558 - val_loss: 0.2910 - val_accuracy: 0.8529\n",
      "Epoch 138/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2534 - accuracy: 0.8574 - val_loss: 0.2878 - val_accuracy: 0.8529\n",
      "Epoch 139/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.8558 - val_loss: 0.2909 - val_accuracy: 0.8529\n",
      "Epoch 140/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2516 - accuracy: 0.8558 - val_loss: 0.2887 - val_accuracy: 0.8529\n",
      "Epoch 141/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.8574 - val_loss: 0.2893 - val_accuracy: 0.8529\n",
      "Epoch 142/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.8732 - val_loss: 0.2850 - val_accuracy: 0.8529\n",
      "Epoch 143/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.8621 - val_loss: 0.2830 - val_accuracy: 0.8529\n",
      "Epoch 144/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2488 - accuracy: 0.8685 - val_loss: 0.2854 - val_accuracy: 0.8529\n",
      "Epoch 145/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.8574 - val_loss: 0.2799 - val_accuracy: 0.8529\n",
      "Epoch 146/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.8574 - val_loss: 0.2849 - val_accuracy: 0.8529\n",
      "Epoch 147/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8875 - val_loss: 0.2822 - val_accuracy: 0.8824\n",
      "Epoch 148/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2433 - accuracy: 0.8780 - val_loss: 0.2772 - val_accuracy: 0.8529\n",
      "Epoch 149/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2426 - accuracy: 0.8574 - val_loss: 0.2785 - val_accuracy: 0.8529\n",
      "Epoch 150/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2422 - accuracy: 0.8843 - val_loss: 0.2806 - val_accuracy: 0.8824\n",
      "Epoch 151/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2412 - accuracy: 0.8748 - val_loss: 0.2751 - val_accuracy: 0.8529\n",
      "Epoch 152/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2388 - accuracy: 0.8605 - val_loss: 0.2826 - val_accuracy: 0.8824\n",
      "Epoch 153/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2382 - accuracy: 0.9160 - val_loss: 0.2773 - val_accuracy: 0.8824\n",
      "Epoch 154/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2375 - accuracy: 0.8906 - val_loss: 0.2752 - val_accuracy: 0.8529\n",
      "Epoch 155/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2363 - accuracy: 0.8700 - val_loss: 0.2735 - val_accuracy: 0.8529\n",
      "Epoch 156/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2348 - accuracy: 0.8843 - val_loss: 0.2756 - val_accuracy: 0.8824\n",
      "Epoch 157/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2339 - accuracy: 0.8922 - val_loss: 0.2719 - val_accuracy: 0.8824\n",
      "Epoch 158/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2344 - accuracy: 0.9017 - val_loss: 0.2751 - val_accuracy: 0.9412\n",
      "Epoch 159/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2340 - accuracy: 0.8827 - val_loss: 0.2703 - val_accuracy: 0.8529\n",
      "Epoch 160/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2328 - accuracy: 0.8700 - val_loss: 0.2722 - val_accuracy: 0.8529\n",
      "Epoch 161/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2314 - accuracy: 0.8605 - val_loss: 0.2680 - val_accuracy: 0.8529\n",
      "Epoch 162/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2310 - accuracy: 0.8669 - val_loss: 0.2736 - val_accuracy: 0.8824\n",
      "Epoch 163/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2302 - accuracy: 0.9429 - val_loss: 0.2679 - val_accuracy: 0.9706\n",
      "Epoch 164/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2278 - accuracy: 0.9382 - val_loss: 0.2699 - val_accuracy: 0.9412\n",
      "Epoch 165/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2267 - accuracy: 0.9540 - val_loss: 0.2705 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2278 - accuracy: 0.9414 - val_loss: 0.2659 - val_accuracy: 0.9706\n",
      "Epoch 167/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2266 - accuracy: 0.8938 - val_loss: 0.2624 - val_accuracy: 0.8529\n",
      "Epoch 168/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2252 - accuracy: 0.9113 - val_loss: 0.2662 - val_accuracy: 0.9706\n",
      "Epoch 169/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2243 - accuracy: 0.9620 - val_loss: 0.2636 - val_accuracy: 0.9706\n",
      "Epoch 170/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2226 - accuracy: 0.9635 - val_loss: 0.2656 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2219 - accuracy: 0.9683 - val_loss: 0.2630 - val_accuracy: 0.9706\n",
      "Epoch 172/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2209 - accuracy: 0.9635 - val_loss: 0.2612 - val_accuracy: 0.9706\n",
      "Epoch 173/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2203 - accuracy: 0.9493 - val_loss: 0.2615 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2201 - accuracy: 0.9572 - val_loss: 0.2631 - val_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2195 - accuracy: 0.9319 - val_loss: 0.2576 - val_accuracy: 0.9412\n",
      "Epoch 176/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2185 - accuracy: 0.9667 - val_loss: 0.2628 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2181 - accuracy: 0.9540 - val_loss: 0.2561 - val_accuracy: 0.9706\n",
      "Epoch 178/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2176 - accuracy: 0.9746 - val_loss: 0.2583 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.9540 - val_loss: 0.2595 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2154 - accuracy: 0.9842 - val_loss: 0.2538 - val_accuracy: 0.9706\n",
      "Epoch 181/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2155 - accuracy: 0.9414 - val_loss: 0.2558 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2138 - accuracy: 0.9651 - val_loss: 0.2527 - val_accuracy: 0.9706\n",
      "Epoch 183/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2131 - accuracy: 0.9731 - val_loss: 0.2548 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2135 - accuracy: 0.9477 - val_loss: 0.2522 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2115 - accuracy: 0.9746 - val_loss: 0.2519 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2111 - accuracy: 0.9778 - val_loss: 0.2509 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2104 - accuracy: 0.9778 - val_loss: 0.2532 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2095 - accuracy: 0.9509 - val_loss: 0.2518 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2094 - accuracy: 0.9667 - val_loss: 0.2495 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2087 - accuracy: 0.9889 - val_loss: 0.2504 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2085 - accuracy: 0.9667 - val_loss: 0.2477 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2061 - accuracy: 0.9826 - val_loss: 0.2499 - val_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2065 - accuracy: 0.9826 - val_loss: 0.2461 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2055 - accuracy: 0.9826 - val_loss: 0.2463 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2046 - accuracy: 0.9762 - val_loss: 0.2452 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2043 - accuracy: 0.9588 - val_loss: 0.2453 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2030 - accuracy: 0.9715 - val_loss: 0.2446 - val_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2028 - accuracy: 0.9778 - val_loss: 0.2467 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2012 - accuracy: 0.9762 - val_loss: 0.2428 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2006 - accuracy: 0.9826 - val_loss: 0.2441 - val_accuracy: 1.0000\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1998 - accuracy: 0.9794\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2441 - accuracy: 1.0000\n",
      "Training Accuracy: 97.94%\n",
      "Test Accuracy: 100.00%\n",
      "Layer 1 - Weights:\n",
      " [[-9.8180331e-02  1.3192399e+00 -9.4811559e-02  7.9056239e-01\n",
      "   3.0558255e+00 -2.4061432e+00  1.5731661e-02 -2.6245388e-01\n",
      "  -3.8324019e-01 -2.6186630e-01 -5.6756669e-01  2.0460761e-01\n",
      "  -1.5860777e-01  3.2934529e-01 -3.1848139e-01]\n",
      " [ 3.6039242e-01  1.3836999e+00 -3.8076693e-01 -1.5627399e-01\n",
      "   1.2428160e+00 -8.7265760e-01  5.6904596e-01 -3.1569335e-01\n",
      "   2.5738159e-01 -1.5490690e-01  6.2743831e-01 -4.3695807e-01\n",
      "  -3.1228149e-01 -3.9576316e-01 -5.1869553e-01]\n",
      " [-9.0524769e-01  5.3808230e-01  3.0542850e-01  1.4171979e+00\n",
      "   3.3256674e-01 -2.0450497e+00 -1.3519180e+00  4.1453391e-01\n",
      "   1.4272163e-03  3.6755317e-01 -1.1603684e+00  4.8782676e-01\n",
      "   3.0564845e-02 -5.2732396e-01 -2.0308313e-01]\n",
      " [-5.1942396e-01  8.8335484e-01  3.9572281e-01  2.2865102e-01\n",
      "   8.1378162e-01 -1.9638786e+00 -3.0486897e-01 -1.9186738e-01\n",
      "   1.4666386e-01 -1.6989386e-01  8.3277720e-01 -5.4965460e-01\n",
      "  -4.5072916e-01  6.4735353e-02  4.1264951e-01]\n",
      " [-4.4560996e-01  3.8872883e-01 -4.5103121e-01  1.0372542e+00\n",
      "   5.3571314e-01 -1.6864270e+00  2.2401616e-01  6.6633523e-02\n",
      "  -4.0427768e-01  9.9594817e-03 -1.1267920e-01  3.4445775e-01\n",
      "   5.4389101e-01  1.8033090e-01 -3.9073229e-03]]\n",
      "\n",
      "Layer 1 - Biases:\n",
      " [ 0.78905904  0.5784754   0.         -0.20275837 -0.40283212  1.1644777\n",
      "  0.35123855 -0.00514247 -0.01699449 -0.00515357  0.19779488 -0.03612271\n",
      " -0.00515211 -0.00514015  0.        ]\n",
      "\n",
      "Layer 2 - Weights:\n",
      " [[ 6.43422782e-01  3.40398372e-04 -5.29012501e-01  1.14667284e+00\n",
      "   9.98551965e-01  1.44519365e+00  4.91973639e-01  3.43521088e-01]\n",
      " [ 9.62177336e-01 -4.40299511e-01  1.29048407e+00 -1.57143489e-01\n",
      "  -2.15535704e-03  2.36929819e-01 -6.30849659e-01 -4.25845012e-02]\n",
      " [ 1.73616588e-01 -3.11905324e-01 -2.90128976e-01  2.08739877e-01\n",
      "  -9.16160941e-02 -4.11821216e-01 -3.83251280e-01 -8.43121409e-02]\n",
      " [-1.05029082e+00 -6.54846430e-03  1.29045773e+00 -2.30020452e+00\n",
      "  -6.93280458e-01 -1.76238275e+00 -1.20102119e+00  1.22866213e+00]\n",
      " [-5.17921150e-01 -4.92879450e-01  1.86409020e+00 -2.35976577e+00\n",
      "   3.75956059e-01  2.84697805e-02 -2.85660625e+00 -2.46759474e-01]\n",
      " [-2.44472933e+00 -7.68448263e-02 -1.45518911e+00  3.18613052e+00\n",
      "   1.78499591e+00  1.22277045e+00  2.10009742e+00  1.71335208e+00]\n",
      " [ 9.64725673e-01  4.43314701e-01 -1.02999878e+00  5.87399423e-01\n",
      "   1.09825277e+00  1.08835506e+00  1.82800576e-01 -1.80841517e+00]\n",
      " [ 1.54335856e-01 -3.40159267e-01 -4.14032131e-01  6.82137981e-02\n",
      "  -3.28536004e-01 -4.79449937e-03 -4.34315532e-01  1.87010884e-01]\n",
      " [-3.84636432e-01  2.54697740e-01  7.52414539e-02 -1.01852156e-01\n",
      "  -4.76443544e-02  1.16149716e-01 -4.23208714e-01 -4.87854242e-01]\n",
      " [ 3.07587206e-01 -4.51469123e-01 -7.74301216e-02  2.14957237e-01\n",
      "  -4.28735077e-01 -3.79853725e-01 -4.11116898e-01 -3.02665472e-01]\n",
      " [ 1.74798310e+00  3.46886545e-01 -2.67419517e-01  6.28833830e-01\n",
      "   6.14275932e-01 -1.00426823e-01 -4.01093334e-01 -1.55084276e+00]\n",
      " [-3.28197002e-01  1.98940814e-01 -4.66137588e-01 -1.89827591e-01\n",
      "  -4.52092081e-01  2.57371902e-01  1.24809653e-01 -1.03196092e-01]\n",
      " [-4.09093380e-01  1.33569539e-01  4.37434971e-01 -2.87614971e-01\n",
      "  -4.45026278e-01 -1.39633995e-02 -9.59075093e-02  2.89577127e-01]\n",
      " [ 3.43010068e-01  1.79656565e-01 -7.58986101e-02  1.33897483e-01\n",
      "  -4.52193081e-01 -6.41695037e-02 -3.08536828e-01  2.74371266e-01]\n",
      " [-3.99547219e-01  4.99159038e-01  1.18196487e-01  4.23839033e-01\n",
      "   4.96420324e-01 -4.77044284e-01 -1.52514011e-01  4.11016166e-01]]\n",
      "\n",
      "Layer 2 - Biases:\n",
      " [ 0.6270914  -0.01611324  0.0361886   0.36470598  0.07628674  0.4092654\n",
      "  0.29593942  0.4188261 ]\n",
      "\n",
      "Layer 3 - Weights:\n",
      " [[-1.7644453   0.99012446 -0.06824843  1.7002444   0.39561418 -2.2487998 ]\n",
      " [-0.23652393  0.03554043  0.4067599  -0.23138107 -0.46645096 -0.07222383]\n",
      " [ 1.0420333  -1.6086143  -1.0809544   0.1804224   0.85051626 -0.60671335]\n",
      " [-0.7058884   1.131019    0.6499093  -2.1210449  -1.7778326   0.6596131 ]\n",
      " [-1.9632035   0.28023675  0.85509956 -0.1131083   1.0656755   0.8827117 ]\n",
      " [-0.75987256 -0.0443735   1.0485371  -0.14812693 -3.002738    0.10270439]\n",
      " [ 0.04535875  1.564129   -2.9903226  -1.2822828  -0.32779527  2.382335  ]\n",
      " [ 1.833578   -0.50584924 -2.1277294  -1.063904   -2.7688127   1.7635028 ]]\n",
      "\n",
      "Layer 3 - Biases:\n",
      " [ 0.02719244  0.20696507 -0.39281777  0.14795905  0.36482835 -0.45234653]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=30)\n",
    "\n",
    "y_train_encoded = to_categorical(y_train, num_classes=6)\n",
    "y_test_encoded = to_categorical(y_test, num_classes=6)\n",
    "\n",
    "# Define the neural network model using Keras\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "# Input Layer and Hidden Layer 1\n",
    "model.add(Dense(15, input_dim=5, activation='relu'))\n",
    "# Hidden Layer 2\n",
    "model.add(Dense(8, activation='relu'))\n",
    "# Output Layer\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train_encoded, epochs=200, batch_size=32, validation_data=(X_test, y_test_encoded), verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "train_loss, train_accuracy = model.evaluate(X_train, y_train_encoded, verbose=1)\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded, verbose=1)\n",
    "\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "for layer_num, layer in enumerate(model.layers):\n",
    "    weights = layer.get_weights()[0]\n",
    "    biases = layer.get_weights()[1]\n",
    "    \n",
    "    print(f\"Layer {layer_num + 1} - Weights:\\n {weights}\\n\")\n",
    "    print(f\"Layer {layer_num + 1} - Biases:\\n {biases}\\n\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d57ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(index=2).output)\n",
    "input_data = tf.constant([[979,179,786,860]]) # Örnek girdi verisi\n",
    "intermediate_output = intermediate_layer_model.predict(input_data)\n",
    "print(intermediate_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483e2788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sample_input = np.array([[355,982,768,59]])  # Example input data\n",
    "logits_output = model.predict(sample_input)\n",
    "\n",
    "print(logits_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed4477e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
